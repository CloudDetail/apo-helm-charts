global:
  edition: ee
  language: en # en | zh
  baseURL: ""

  image:
    # -- Docker image repository
    # docker.io/clouddetail (default)
    # registry.cn-hangzhou.aliyuncs.com/kindlingx
    repository: "docker.io/clouddetail"
    eeRepository: "docker.io/clouddetail"
    pullPolicy: "Always"
  
  persistence:
    enabled: false
    storageClass: ""

  # APO Collection Modes  
  # - trace              Full data collection, automatically injects trace collection probes  
  # - trace-collector    Use collector to receive trace data from external probes  
  # - trace-sidecar      Do not accept external trace data, directly retrieve data from external APIs, this mode requires configuring external API data sources
  # - no-trace           Do not collect trace data
  # - metrics            Full metrics data collection  
  # - log                Full log collection, including fault scenario logs  
  # - log-sample         Fault scenario log collection, without collecting full logs  
  agentCollectorMode:
    - trace
    - metrics
    - log
  victoriaMetrics:
    # victoriaMetrics-single(single) or victoriaMetrics-cluster(cluster)
    # After switching modes, the corresponding URL for the mode needs to be provided.
    mode: single 
    single:
      url: "http://apo-victoria-metrics-single-server-svc:8428"
    cluster:
      # selectUrl: "http://<vmselect>:8481/select/<accountID>/prometheus"
      selectUrl: http://read-service-url:8080/select/0/prometheus/
      # insertUrl: "http://<vmselect>:8481/select/<accountID>/prometheus"
      insertUrl: http://write-service-url:8080/insert/0/prometheus/

  clickhouse:
    host: "apo-clickhouse-svc"
    nativePort: 9000
    httpPort: 8123
    username: admin
    password: "WPKf-e9U.X)K)ezTDo9#"
    database: "apo"
    clusterName: ""
    replication: "false"

  postgres:
    host: "apo-postgres-svc"
    port: 5432
    username: postgres
    password: Postgres@123456
    apoDifyDatabase: apo_dify
    apoDifyPluginDatabase: apo_dify_plugin
    apoGrafanaDatabase: apo_grafana
    apoBackendDatabase: apo_backend
  
  redis:
    host: "apo-redis-svc"
    port: 6379
    username: ""
    password: Redis@123456

  # deepflow integration configuration, requires a separate installation of the deepflow v6.4 TLS version  
  deepflow:
    enabled: false
    mysql:
      address: "deepflow-mysql:30130"
      username: root
      password: deepflow
      dbname: deepflow
    clickhouse:
      address: "deepflow-clickhouse:9000"
      username: ""
      password: ""

  # -- Pod's node selector. Ref: [https://kubernetes.io/docs/user-guide/node-selection/](https://kubernetes.io/docs/user-guide/node-selection/)
  nodeSelector: {}
  # nodeSelector:
  #   kubernetes.io/hostname: demo-node

  # -- Pod affinity
  affinity: {}
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: topology.kubernetes.io/zone
  #           operator: In
  #           values:
  #           - antarctica-east1

  # -- Node tolerations for server scheduling to nodes with taints. Ref: [https://kubernetes.io/docs/concepts/configuration/assign-pod-node/](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/)
  tolerations: []
  # tolerations:
  # - key: "key"
  #   operator: "Equal|Exists"
  #   value: "value"
  #   effect: "NoSchedule|PreferNoSchedule"

apo-backend:
  enabled: true
  initImage:
    repository: "{{ .Values.global.image.repository }}/busybox"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.36.1"
  apoBackend:
    image:
      registry: "{{ .Values.global.image.repository }}"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.8.0-beta.1"
    # resources:
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi
  apoPolarisAnalyzer:
    image:
      repository: "{{ .Values.global.image.repository }}/polaris-analyzer"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.1.3"
    resources:
      limits:
        # cpu: 1000m
        memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi
  service:
    type: NodePort
    nodePort: 31363
  config:
    clickhouseUrl: "{{ .Values.global.clickhouse.host }}:{{ .Values.global.clickhouse.nativePort }}"
    clickhouseUsername: "{{ .Values.global.clickhouse.username }}"
    clickhousePassword: "{{ .Values.global.clickhouse.password }}"
    anonymousUserEnabled: "false"
  nodeSelector: {}
  affinity: {}
  tolerations: []

apo-collector:
  enabled: true
  initImage:
    repository: "{{ .Values.global.image.repository }}/busybox"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.36.1"
  apoCollector:
    image:
      repository: "{{ .Values.global.image.repository }}/apo-collector"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.8.1"
    # resources: 
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi
    service:
      type: NodePort
      port: 29090
      targetPort: 29090
      nodePortGrpc: 30044
      nodePortHttp: 30090
    config:
      clickhouseUrl: "{{ .Values.global.clickhouse.host }}:{{ .Values.global.clickhouse.nativePort }}"
      clickhouseUsername: "{{ .Values.global.clickhouse.username }}"
      clickhousePassword: "{{ .Values.global.clickhouse.password }}"
      apmAdapterUrl: "apo-apm-adapter-svc:8079"
      apoBackendUrl: "http://apo-backend-svc:8080"

  apoApmAdapter:
    image:
      repository: "{{ .Values.global.image.repository }}/apm-adapter"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.8.0"
    # resources: 
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi
    service:
      port: 8079
    config:
      adapter:
        # Expose HTTP port. 
        http_port: 8079
        # Set HTTP request timeout; if it times out, a response is returned directly.  
        timeout: 10  
        # APM system integration.  
        trace_api:  
          # Enable the APM integration list  
          apm_list: [skywalking, jaeger, elastic]  
          datadog:  
            site: "datadoghq.com"
            api_key: ""
            app_key: ""
          # Skywalking configuration
          skywalking:
            # No need to include the http or https protocol prefix.
            address: ""  
            user: ""  
            password: ""  
          # Jaeger configuration  
          jaeger:
            # No need to include the http or https protocol prefix.
            address: apo-jaeger-collector-svc:16686/jaeger  
          # Tingyun3-related configuration  
          nbs3:
            # No need to include the http or https protocol prefix.
            address: ""  
            user: ""  
            password: ""  
          # Arms-related configuration  
          arms:
            # No need to include the http or https protocol prefix.
            address: "arms.cn-hangzhou.aliyuncs.com"  
            access_key: ""  
            access_secret: ""  
          elastic:  
            # You can add protocol prefixes 'https://' or 'http://', default is http  
            address: ""  
            user: ""  
            password: ""  
          # Pinpoint configuration  
          pinpoint:
            # No need to include the http or https protocol prefix.
            address: ""  
  nodeSelector: {}
  tolerations: []
  affinity: {}

apo-dify:
  enabled: true

  api:
    initImage:
      repository: "{{ .Values.global.image.repository }}/apo-init-postgres"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.0"
    image:
      repository: "{{ .Values.global.image.repository }}/apo-dify-api"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.0-7"
    persistent:
      enabled: "{{ .Values.global.persistence.enabled }}"
      accessModes:
        - ReadWriteOnce
      storageClass: "{{ .Values.global.persistence.storageClass }}"
      size: 10Gi

  pluginDaemon:
    initImage:
      repository: "{{ .Values.global.image.repository }}/apo-init-postgres"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.0"
    InitPluginImage:
      repository: "{{ .Values.global.image.repository }}/apo-dify-plugin-init"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.1"
    image:
      repository: "{{ .Values.global.image.repository }}/dify-plugin-daemon"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "0.0.7-local"
    persistent:
      enabled: "{{ .Values.global.persistence.enabled }}"
      accessModes:
        - ReadWriteOnce
      storageClass: "{{ .Values.global.persistence.storageClass }}"
      size: 10Gi

  sandbox:
    image:
      repository: "{{ .Values.global.image.repository }}/dify-sandbox"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "0.2.10"

  ssrf:
    image:
      repository: "{{ .Values.global.image.repository }}/ubuntu-squid"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "6.6-24.04_edge"

  web:
    image:
      repository: "{{ .Values.global.image.repository }}/apo-dify-web"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.0-5"

  worker:
    image:
      repository: "{{ .Values.global.image.repository }}/apo-dify-api"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.0-6"

  nodeSelector: {}
  tolerations: []
  affinity: {}

apo-front:
  enabled: true
  image:
    registry: "{{ .Values.global.image.repository }}"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "v1.8.0-beta.1"
  # resources: 
  #   limits:
  #     cpu: 1000m
  #     memory: 1024Mi
  #   requests:
  #     cpu: 100m
  #     memory: 128Mi
  service:
    type: NodePort
    nodePort: 31364
  config:
    apoJaegerCollectorUrl: "http://apo-jaeger-collector-svc:16686"
    apoGrafanaUrl: "http://apo-grafana-svc:80"
    apoBackendUrl: "http://apo-backend-svc:8080"
  nodeSelector: {}
  tolerations: []
  affinity: {}

apo-jaeger-collector:
  enabled: true
  initImage:
    repository: "{{ .Values.global.image.repository }}/busybox"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.36.1"
  remoteStorage:
    image:
      repository: "{{ .Values.global.image.repository }}/jaeger-remote-storage"
      pullPolicy: IfNotPresent
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.0.0"
    # resources: 
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi

  jaegerQuery:
    image:
      repository: "{{ .Values.global.image.repository }}/jaeger-query"
      tag: 1.58
    # resources: 
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi

  jaegerCollector:
    image:
      repository: "{{ .Values.global.image.repository }}/jaeger-collector"
      tag: "1.59-latest"
    # resources: 
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 100m
    #     memory: 128Mi
  config:
    clickhouseUrl: "{{ .Values.global.clickhouse.host }}:{{ .Values.global.clickhouse.nativePort }}"
    clickhouseUsername: "{{ .Values.global.clickhouse.username }}"
    clickhousePassword: "{{ .Values.global.clickhouse.password }}"
  nodeSelector: {}
  affinity: {}
  tolerations: []

apo-one-agent:
  enabled: false
  apoOneAgent:
    image:
      repository: "{{ .Values.global.image.repository }}/ebpf-agent"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.9.3"
    resources: 
      limits:
        cpu: 1000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    config:
      apoCollectorUrl: "apo-collector-svc.{{ .Release.Namespace }}"
      apoCollectorPort: "29090"

  apoNodeAgent:
    image:
      repository: "{{ .Values.global.image.repository }}/node-agent"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.8.0"
    resources:
      limits:
        cpu: 200m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi
    apoOtelCollectorUrl: "apo-otel-collector-gateway-svc:8080"

  apoIlogtail:
    image:
      repository: "{{ .Values.global.image.repository }}/ilogtail"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.5.2"
    resources: 
      limits:
        cpu: 1000m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
    apoOtelCollectorGrpcUrl: "apo-otel-collector-gateway-svc:4315"
    apoVectorLogUrl: "apo-vector-svc:4310"

  grafanaAlloy:
    image:
      repository: "{{ .Values.global.image.repository }}/grafana-alloy"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.4.2-1"
    resources: 
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
    config:
      apoOtelCollectorGrpcUrl: "apo-otel-collector-gateway-svc:4315"
      apoOtelCollectorHttpUrl: "apo-otel-collector-gateway-svc:4316"
  
  grafanaBeyla:
    enabled: false
    image:
      repository: "{{ .Values.global.image.repository }}/apo-beyla"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.8.4-1"
    resources: 
      limits:
        cpu: 1000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    config:
      k8sNamespace: "^/(/?/!{{ .Release.Namespace }}$).*"

  odiglet:
    image:
      repository: "{{ .Values.global.image.repository }}/apo-odiglet"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.3"
      resources: 
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 100m
          memory: 128Mi
    apoOtelCollectorGrpcUrl: "apo-otel-collector-svc.{{ .Release.Namespace }}:4317"
    apoOtelCollectorHttpUrl: "apo-otel-collector-svc.{{ .Release.Namespace }}:4318"
    apoOtelCollectorSkywalkingUrl: "apo-otel-collector-svc.{{ .Release.Namespace }}:11800"

  apoOtelCollectorAgent:
    image:
      repository: "{{ .Values.global.image.repository }}/apo-otel-collector"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.3.1"
      resources: 
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
    config:
      apoCollectorUrl: "apo-collector-svc"
      apoCollectorPort: "29090"
      apoOtelCollectorUrl: "apo-otel-collector-gateway-svc"
      apoOtelCollectorGRPCPort: "4315"

  originxGcAgent:
    image:
      repository: "{{ .Values.global.image.eeRepository }}/originx-gc-agent"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.4.1"
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 10m
        memory: 64Mi
    config:
      apoCollectorUrl: "apo-collector-svc"
      apoCollectorPort: "29090"

  profileAgent:
    enabled: true
    image:
      repository: "{{ .Values.global.image.eeRepository }}/profile-agent"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.0.0"
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
    config:
      apoCollectorUrl: "apo-collector-svc"
      apoCollectorPort: "29090"

  vmagent:
    image:
      repository: "{{ .Values.global.image.repository }}/vmagent"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      tag: "v1.102.1"
    resources:
      limits:
        cpu: 1000m
        memory: 1024Mi
      requests:
        cpu: 10m
        memory: 64Mi
    remoteWriteUrls: "http://apo-otel-collector-gateway-svc:4321"

  odigos:
    enabled: true
    instrumentor:
      image:
        repository: "{{ .Values.global.image.repository }}/apo-odigos-instrumentor"
        imagePullPolicy: "{{ .Values.global.image.pullPolicy }}"
        tag: "v1.0.6"
      resources:
        limits:
          cpu: 1000m
          memory: 1024Mi
        requests:
          cpu: 10m
          memory: 64Mi
      # targetNamespace  
      # name: Target namespace  
      # value:  
      #   enabled: Inject all existing services but do not inject newly added applications  
      #   enabledFuture: Inject both current and future services  
      #   disabled: Do not inject services in the specified namespace; used to exclude specific namespaces when instrument-all-namespace is enabled  
      # targetNamespace:  
      # - name: default  
      #   value: disabled  
      # instrument-all-namespace Whether to inject all namespaces  
      # Equivalent to setting enabledFuture for all namespaces  
      # However, if disabled is already set for a namespace or workload, it will not be injected  
      instrumentAllNamespace: true
      # force-instrument-all-namespace Whether to force inject all namespaces  
      # Similar to instrument-all-namespace, sets enabledFuture for all namespaces  
      # Ignores all disabled settings  
      forceInstrumentAllNamespace: false
      # enableOverwriteUserDefinedEnvs: Whether to overwrite user-defined environment variables
      enableOverwriteUserDefinedEnvs: false
    config:
      apoOtelCollectorGrpcUrl: "apo-otel-collector-gateway-svc.{{ .Release.Namespace }}:4315"
      apoOtelCollectorHttpUrl: "apo-otel-collector-gateway-svc.{{ .Release.Namespace }}:4316"
      apoOtelCollectorSkywalkingUrl: "apo-otel-collector-gateway-svc.{{ .Release.Namespace }}:11800"
      javaAgentType: "opentelemetry"

  apo-nginx-proxy:
    enabled: false
    image:
      repository: "{{ .Values.global.image.repository }}/nginx"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "stable-alpine3.20"

  apo-otel-collector:
    enabled: false

  nodeSelector: {}
  affinity: {}
  tolerations: []

apo-otel-collector-gateway:
  enabled: true
  initImage:
    repository: "{{ .Values.global.image.repository }}/busybox"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.36.1"
  image:
    repository: "{{ .Values.global.image.repository }}/apo-otel-collector"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "v1.3.1"
  config:
    apoBackendUrl: "apo-backend-svc"
    apoBackendPort: "8080"
    jaegerCollectorUrl: "http://apo-jaeger-collector-svc:4317"
    clickhouseUrl: "{{ .Values.global.clickhouse.host }}:{{ .Values.global.clickhouse.nativePort }}"
    clickhouseUsername: "{{ .Values.global.clickhouse.username }}"
    clickhousePassword: "{{ .Values.global.clickhouse.password }}"
  serviceNodePort:
    ports:
    - name: otlpgrpc
      protocol: TCP
      port: 4317
      targetPort: 4317
      nodePort: 30317
    - name: otlpk8s
      protocol: TCP
      port: 4319
      targetPort: 4319
      nodePort: 30319
    - name: vmremotewrite
      protocol: TCP
      port: 4321
      targetPort: 4321
      nodePort: 30321
    type: NodePort
  resources: 
    limits:
      cpu: 3000m
      memory: 3072Mi
    requests:
      cpu: 100m
      memory: 128Mi
  rbac:
    create: true
  nodeSelector: {}
  affinity: {}
  tolerations: []

altinity-clickhouse-operator:
  enabled: true
  operator:
    image:
      # operator.image.repository -- image repository
      repository: "{{ .Values.global.image.repository }}/clickhouse-operator"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
  metrics:
    enabled: true
    image:
      # metrics.image.repository -- image repository
      repository: "{{ .Values.global.image.repository }}/metrics-exporter"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
  nodeSelector: {}
  tolerations: []
  affinity: {}
  clickhouse:
    image:
      repository: "{{ .Values.global.image.repository }}/clickhouse-server"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    username: "{{ .Values.global.clickhouse.username }}"
    password: "{{ .Values.global.clickhouse.password }}"
    persistence:
      # -- Create/use Persistent Volume Claim for server component. Empty dir if false
      enabled: "{{ .Values.global.persistence.enabled }}"
      
      data:
        # -- Array of access modes. Must match those of existing PV or dynamic provisioner. Ref: [http://kubernetes.io/docs/user-guide/persistent-volumes/](http://kubernetes.io/docs/user-guide/persistent-volumes/)
        accessModes:
          - ReadWriteOnce

        # -- StorageClass to use for persistent volume. Requires clickhouse.persistence.enabled: true. If defined, PVC created automatically
        storageClass: "{{ .Values.global.persistence.storageClass }}"

        # -- Bind Persistent Volume by labels. Must match all labels of targeted PV.
        matchLabels: {}

        # -- Size of the volume. Should be calculated based on the metrics you send and retention policy you set.
        size: 16Gi
      
      log:
        # -- Array of access modes. Must match those of existing PV or dynamic provisioner. Ref: [http://kubernetes.io/docs/user-guide/persistent-volumes/](http://kubernetes.io/docs/user-guide/persistent-volumes/)
        accessModes:
          - ReadWriteOnce

        # -- StorageClass to use for persistent volume. Requires clickhouse.persistence.enabled: true. If defined, PVC created automatically
        storageClass: "{{ .Values.global.persistence.storageClass }}"

        # -- Bind Persistent Volume by labels. Must match all labels of targeted PV.
        matchLabels: {}

        # -- Size of the volume. Should be calculated based on the metrics you send and retention policy you set.
        size: 1Gi
    nodeSelector: {}
    tolerations: []
    affinity: {}

grafana:
  enabled: true
  image:
    registry: "{{ .Values.global.image.repository }}"
    # -- Docker image repository
    repository: grafana
    # Overrides the Grafana image tag whose default is the chart appVersion
    tag: "10.4.1"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
  extraInitContainers: 
  - name: init-postgres
    image: "{{ .Values.global.image.repository }}/apo-init-postgres:v1.0.0"
    imagePullPolicy: "{{ .Values.global.image.pullPolicy }}"
    env:
      - name: POSTGRES_HOST
        value: "{{ .Values.global.postgres.host }}"
      - name: POSTGRES_PORT
        value: "{{ .Values.global.postgres.port }}"
      - name: POSTGRES_USER
        value: "{{ .Values.global.postgres.username }}"
      - name: POSTGRES_PASSWORD
        value: "{{ .Values.global.postgres.password }}"
      - name: INIT_DB_NAME
        value: "{{ .Values.global.postgres.apoGrafanaDatabase }}"
  - name: apo-grafana-init-dashboard
    image: "{{ .Values.global.image.repository }}/apo-grafana-init-dashboards:v1.3.3-beta.4"
    imagePullPolicy: "{{ .Values.global.image.pullPolicy }}"
    volumeMounts:
    - name: apo-dashboards
      mountPath: /var/lib/grafana/dashboards
    - name: apo-plugins
      mountPath: /var/lib/grafana/plugins
    - name: apo-dashboardproviders
      mountPath: /etc/grafana/provisioning/dashboards
  grafana.ini:
    server:
      domain: "localhost"
  # resources: 
  #   limits:
  #     cpu: 1000m
  #     memory: 1024Mi
  #   requests:
  #     cpu: 100m
  #     memory: 128Mi
  rbac:
    create: false
  nodeSelector: {}
  affinity: {}
  tolerations: []

originx-copilot-ai:
  enabled: true
  image:
    registry: "{{ .Values.global.image.eeRepository }}"
    repository: originx-copilot
    tag: "v1.1.4"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
  resources:
    limits:
      cpu: 1000m
      memory: 1024Mi
    requests:
      cpu: 100m
      memory: 128Mi
  service:
    type: ClusterIP
    port: 10088
    targetPort: 10088
    nodePort: null
  config:
    apoBackendUrl: http://apo-backend-svc:8080
    apoPolarisBackendUrl: http://apo-polaris-analyzer-svc:5000
    originxRootCauseInferUrl: http://originx-root-cause-infer-svc:8080
  nodeSelector: {}
  affinity: {}
  tolerations: []

originx-root-cause-infer:
  enabled: true
  initImage:
    repository: "{{ .Values.global.image.repository }}/busybox"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.36.1"
  image:
    repository: "{{ .Values.global.image.eeRepository }}/root-cause-infer"
    tag: "v1.6.5"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
  resources: 
    limits:
      cpu: 1000m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  nodeSelector: {}
  affinity: {}
  tolerations: []

postgres:
  enabled: true
  image:
    repository: "{{ .Values.global.image.repository }}/postgres"
    # This sets the pull policy for images.
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "15-alpine"
  server:
    username: "{{ .Values.global.postgres.username }}"
    password: "{{ .Values.global.postgres.password }}"
  service:
    type: ClusterIP
    port: "{{ .Values.global.postgres.port }}"
  persistent:
    enabled: "{{ .Values.global.persistence.enabled }}"
    accessModes:
      - ReadWriteOnce
    storageClass: "{{ .Values.global.persistence.storageClass }}"
    size: 10Gi
  nodeSelector: {}
  affinity: {}
  tolerations: []

redis:
  enabled: true
  image:
    repository: "{{ .Values.global.image.repository }}/redis"
    # This sets the pull policy for images.
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "6-alpine"
  nodeSelector: {}
  affinity: {}
  tolerations: []

vector:
  enabled: true
  image:
    repository: "{{ .Values.global.image.repository }}/vector"
    tag: "0.41.1-distroless-libc"
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
  service:
    type: NodePort
    ports:
    - name: datadog-agent
      port: 4310
      targetPort: 4310
      nodePort: 30310
      protocol: TCP
  resources: 
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 2000m
      memory: 2048Mi
  role: Stateless-Aggregator
  fullnameOverride: "apo-vector"
  clickhouseUrl: "{{ .Values.global.clickhouse.host }}:{{ .Values.global.clickhouse.nativePort }}"
  clickhouseUsername: "{{ .Values.global.clickhouse.username }}"
  clickhousePassword: "{{ .Values.global.clickhouse.password }}"
  nodeSelector: {}
  affinity: {}
  tolerations: []

victoria-metrics-alert:
  enabled: true
  server:
    image:
      repository: "{{ .Values.global.image.repository }}/vmalert"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.102.0"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # resources:
    #   limits:
    #     cpu: 1000m
    #     memory: 1024Mi
    #   requests:
    #     cpu: 500m
    #     memory: 512Mi
  alertmanager:
    enabled: true
    image: "{{ .Values.global.image.repository }}/alertmanager"
    tag: v0.25.0
    extraContainers:
    - name: alertmanager-configmap-reload
      image: "{{ .Values.global.image.repository }}/alertmanager-configmap-reload:v0.9.0"
      imagePullPolicy: "{{ .Values.global.image.pullPolicy }}"
      args:
        - '--volume-dir=/config'
        - '--webhook-url=http://127.0.0.1:9093/-/reload'
      volumeMounts:
        - name: config
          readOnly: true
          mountPath: /config
    config:
      global:
          resolve_timeout: 5m
          http_config:
              follow_redirects: true
              enable_http2: true
          smtp_hello: localhost
          smtp_require_tls: true
          pagerduty_url: https://events.pagerduty.com/v2/enqueue
          opsgenie_api_url: https://api.opsgenie.com/
          wechat_api_url: https://qyapi.weixin.qq.com/cgi-bin/
          victorops_api_url: https://alert.victorops.com/integrations/generic/20131114/alert/
          telegram_api_url: https://api.telegram.org
          webex_api_url: https://webexapis.com/v1/messages
      route:
          receiver: 根告警
          group_by:
              - alertname
          continue: false
          routes:
              - receiver: APO异常检测告警
                matchers: 
                - group=~"mutation.*"
                continue: false
              - receiver: alert-collector
                continue: true
          group_wait: 30s
          group_interval: 1m
          repeat_interval: 30m
      route:
        continue: false
        group_by:
        - alertname
        group_interval: 1m
        group_wait: 30s
        receiver: root
        repeat_interval: 30m
        routes:
        - continue: false
          matchers:
          - group=~"mutation.*"
          receiver: "APO Mutation Check"
        - continue: true
          receiver: "APO Alert Collector"
      receivers:
      - name: root
      - name: "APO Mutation Check"
        webhook_configs:
        - http_config:
            enable_http2: true
            follow_redirects: true
          max_alerts: 0
          send_resolved: true
          url: http://apo-backend-svc:8080/api/alerts/inputs/alertmanager
      - name: "APO Alert Collector"
        webhook_configs:
        - http_config:
            enable_http2: true
            follow_redirects: true
          max_alerts: 0
          send_resolved: true
          url: http://apo-backend-svc:8080/api/alerts/inputs/alertmanager
  rbac:
    create: false
  nodeSelector: {}
  affinity: {}
  tolerations: []

victoria-metrics-single:
  enabled: true
  server:
    image:
      repository: "{{ .Values.global.image.repository }}/victoria-metrics"
      # Overrides the image tag whose default is the chart appVersion.
      tag: "v1.101.0"
      pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    extraArgs:
      envflag.enable: "true"
      envflag.prefix: VM_
      loggerFormat: json
      search.maxSeries: 100000
    # persistentVolume:
    #   enabled: "{{ .Values.global.persistentVolume.enabled }}"
    service:
      type: ClusterIP
      # nodePort: 30428
    persistentVolume:
      # -- Create/use Persistent Volume Claim for server component. Empty dir if false
      enabled: "{{ .Values.global.persistence.enabled }}"

      # -- Array of access modes. Must match those of existing PV or dynamic provisioner. Ref: [http://kubernetes.io/docs/user-guide/persistent-volumes/](http://kubernetes.io/docs/user-guide/persistent-volumes/)
      accessModes:
        - ReadWriteOnce
      # -- Persistant volume annotations
      annotations: {}

      # -- StorageClass to use for persistent volume. Requires server.persistentVolume.enabled: true. If defined, PVC created automatically
      storageClass: "{{ .Values.global.persistence.storageClass }}"

      # -- Existing Claim name. If defined, PVC must be created manually before volume will be bound
      existingClaim: ""

      # -- Bind Persistent Volume by labels. Must match all labels of targeted PV.
      matchLabels: {}

      # -- Mount path. Server data Persistent Volume mount root path.
      mountPath: /storage
      # -- Mount subpath
      subPath: ""
      # -- Size of the volume. Should be calculated based on the metrics you send and retention policy you set.
      size: 16Gi
    # resources:
    #   limits:
    #     cpu: 2000m
    #     memory: 2048Mi
    #   requests:
    #     cpu: 500m
    #     memory: 512Mi
  rbac:
    create: false
  nodeSelector: {}
  affinity: {}
  tolerations: []
  
weaviate:
  enabled: true
  image:
    repository: "{{ .Values.global.image.repository }}/weaviate"
    # This sets the pull policy for images.
    pullPolicy: "{{ .Values.global.image.pullPolicy }}"
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.19.0"
  persistent:
    enabled: "{{ .Values.global.persistence.enabled }}"
    accessModes:
      - ReadWriteOnce
    storageClass: "{{ .Values.global.persistence.storageClass }}"
    size: 10Gi
  nodeSelector: {}
  affinity: {}
  tolerations: []
